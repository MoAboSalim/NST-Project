# NST-Project
Arbitrary Style Transfer with Style-Attentional Networks

ğŸ–¼ï¸ SANet â€“ Neural Style Transfer for Self-Attention
High-Quality Artistic Style Transfer Using Self-Attention Networks

This version of the project performs high-quality Neural Style Transfer using Self-Attention Networks (SANet) with support for:

Object Control (Alpha Mix Control)

Preservation of Original Image Colors (Color Preservation)

Image Size Selection During Inference

Accelerated Training Using Mixed Precision (AMP)

TensorBoard Support

VGG Model Configured to Work with SANet

âœ”ï¸ Self-Attention Style Transfer (SANet)

âœ”ï¸ Adaptive Instance Normalization (AdaIN)

âœ”ï¸ Color Preservation (YUV-based logic)

âœ”ï¸ Fast GPU Inference

âœ”ï¸ Supports Large Images

âœ”ï¸ Training + Evaluation scripts

âœ”ï¸ Clean, optimized PyTorch implementation

ğŸ“ Project Structure
project/
â”‚â”€â”€ eval_clean.py          # Inference / style transfer on images
â”‚â”€â”€ train.py               # Training SANet using content & style datasets
â”‚â”€â”€ vgg_normalised.pth     # Pretrained VGG weights
â”‚â”€â”€ decoder.pth            # Decoder trained weights
â”‚â”€â”€ transformer.pth        # Transform/SANet weights
â”‚â”€â”€ datasets/
â”‚     â”œâ”€â”€ content/
â”‚     â””â”€â”€ style/
â””â”€â”€ output/

The project supports Style Transfer via a Flask API, allowing you to send the Content image and Style image via HTTP request and receive the resulting image ready for quality evaluation.

âš™ï¸ How It Works

The core file for running the API is:

app.py

It contains 3 main operations:
